{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías \n",
    "\n",
    "import pandas as pd  \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver  \n",
    "from webdriver_manager.chrome import ChromeDriverManager  \n",
    "from selenium.webdriver.common.keys import Keys  \n",
    "from selenium.webdriver.support.ui import Select  \n",
    "from time import sleep  \n",
    "\n",
    "pd.set_option('display.max_columns', None)  # Establece una opción de Pandas para mostrar todas las columnas de un DataFrame.\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtraerDatosActoresSelenium:\n",
    "    def __init__(self, archivo_csv): \n",
    "        self.archivo_csv = pd.read_csv(archivo_csv)  \n",
    "        self.info_actores = [] \n",
    "        self.info_actores_tupla = [] \n",
    "        \n",
    "    def pag_principal_google(self):\n",
    "            # Inicializar el driver de Chrome\n",
    "            options = webdriver.ChromeOptions()\n",
    "            options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "            self.driver = webdriver.Chrome(options=options)\n",
    "            sleep(2)\n",
    "            self.driver.maximize_window()\n",
    "            self.driver.get(\"https://www.google.es/\")\n",
    "            # acepta cookies\n",
    "            sleep(5)\n",
    "            try:\n",
    "                self.driver.find_element(\"css selector\", \"#L2AGLb\").click()\n",
    "            except:\n",
    "                pass\n",
    "            self.escoger_actor_csv()          \n",
    "\n",
    "    def escoger_actor_csv(self)\n",
    "        # Itera por cada pelicula del csv\n",
    "        for i in range(10, 20):  \n",
    "            # Escoge info del csv para la busqueda  \n",
    "            actor = (f\"{self.archivo_csv['actor'][i]}\")  \n",
    "            # Mete en la lista el actor  \n",
    "            self.info_actores.append(actor)    \n",
    "            # Busca info del actor      \n",
    "            self.busqueda_google(\"imdb\", actor)                     \n",
    "            self.busqueda_google(\"imdb premios\", actor)\n",
    "            # Si no tiene premios, apendea vacio\n",
    "            if len(self.info_actores) == 4:\n",
    "                self.info_actores.append(\"\")\n",
    "            # Si la lista esta completa apendea la tupla\n",
    "            if len(self.info_actores) > 4:\n",
    "                tupla = tuple(self.info_actores)\n",
    "                print(tupla)\n",
    "                self.info_actores_tupla.append(tupla)\n",
    "            # resetea la lista\n",
    "            self.info_actores.clear()  \n",
    "            # Guarda en archivo\n",
    "            self.guardar_info_actores_csv(\"info_actores\")\n",
    "       \n",
    "    def busqueda_google(self, pagina, dato_buscador):\n",
    "        sleep(3)\n",
    "        # Ingresar el título y año de la película en el campo de búsqueda\n",
    "        self.driver.find_element(\"css selector\", \"#APjFqb\").clear()\n",
    "        self.driver.find_element(\"css selector\", \"#APjFqb\").send_keys(f'{pagina} \"{dato_buscador}\"', Keys.ENTER)             \n",
    "       \n",
    "        # Definimos la url de la página de la que vamos a sacar datos y llama a la api   \n",
    "        try:            \n",
    "            sleep(5)            \n",
    "            href = self.driver.find_element(\"css selector\", \"#rso .yuRUbf > div > span > a\").get_attribute(\"href\")   \n",
    "            # si el primer resultado de google no es de imdb pasa a la siguiente pelicula \n",
    "            if \"imdb\" in href:                                \n",
    "                self.llamada_api(href) \n",
    "            else:\n",
    "                self.info_actores.append(\"\")\n",
    "                print(f\"ha fallado la llamada a la pagina {pagina}\")\n",
    "                \n",
    "        except:\n",
    "            pass    \n",
    "    \n",
    "    def llamada_api (self, href):\n",
    "\n",
    "        # Definimos un User-Agent para que la solicitud parezca venir de un navegador real        \n",
    "        \n",
    "        headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
    "        }\n",
    "              \n",
    "        # Hacemos la request a la página de la que queremos sacar la info (imbd)\n",
    "        resultado = requests.get(href, headers=headers)\n",
    "\n",
    "        # Vemos si todo ha ido bien\n",
    "        print(\"La respuesta de la petición es:\", resultado.status_code)\n",
    "\n",
    "        # creamos el objeto BeautifulSoup para poder acceder al contenido solicitado\n",
    "        sopa = BeautifulSoup(resultado.content, 'html.parser')\n",
    "        # si el objeto viene de imdb premios llamamos a limpiar datos de premios\n",
    "        if resultado.status_code == 200:\n",
    "            if \"award\" in href: \n",
    "                self.limpieza_datos_premios_imdb(sopa)     \n",
    "            # si el objeto viene de imdb llamamos a limpiar datos actor        \n",
    "            else : \n",
    "                self.limpieza_datos_actores_imdb(sopa)          \n",
    "        else:\n",
    "            return         \n",
    "    \n",
    "    def limpieza_datos_actores_imdb(self, sopa):\n",
    "        if len(self.info_actores) == 1 :  \n",
    "            # sacamos año nacimiento        \n",
    "            anho_nacimiento = sopa.find_all(\"span\", {\"class\": \"sc-59a43f1c-2\"})\n",
    "            self.info_actores.append(anho_nacimiento[1].text)\n",
    "            \n",
    "            # pq es conocido\n",
    "            conocido = sopa.find_all(\"a\", {\"class\": \"ipc-metadata-list-summary-item__t\"})\n",
    "            lista =[]\n",
    "            for i in range(0,10):   \n",
    "                lista.append(conocido[i].text)\n",
    "            self.info_actores.append(lista)\n",
    "\n",
    "            # que hace\n",
    "            que_hace = sopa.find_all(\"ul\", {\"class\": \"ipc-inline-list ipc-inline-list--show-dividers sc-d8941411-2 cdJsTz baseAlt\"})\n",
    "            self.info_actores.append(que_hace[0].text)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def limpieza_datos_premios_imdb(self, sopa):\n",
    "        premios = []\n",
    "        # premios\n",
    "        premios_sopa = sopa.find_all(\"a\", {\"class\": \"ipc-metadata-list-summary-item__t\"})\n",
    "        for i in range(0,4):\n",
    "            premios.append(premios_sopa[i].text)\n",
    "        self.info_actores.append(premios)\n",
    "\n",
    "    def guardar_info_actores_csv (self, nombre_archivo):        \n",
    "        try:\n",
    "            df_actores = pd.DataFrame(self.info_actores_tupla, columns=[\"nombre_apellido\", \"anho_nacimiento\", \"peliculas\", \"que_hace\", \"premios\"])\n",
    "            df_actores.to_csv(nombre_archivo+\".csv\", index=False, header=True)\n",
    "        except:\n",
    "            print(\"no puedo convertir a csv\")\n",
    "    \n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hola\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "('Carlos Alberto Riccelli', 'July 3, 1946', ['La vida secreta de las parejas', 'Amor em Sampa', 'Trago Comigo', 'Mandrake (Serie de TV)', 'Guerra dos Sexos', 'Manual Para se Defender de Alienigenas, Zumbis e Ninjas', 'Federal', 'Filhos do Carnaval', 'Trago Comigo', 'Eles Não Usam Black-Tie - Conversando com o Elenco'], 'ActorDirectorProducer', ['1979 Winner APCA Trophy', '1998 Winner Contigo', '2009 Nominee Prêmio Qualidade', '2012 Winner LABRFF Award'])\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "('János Bácskai', 'November 27, 1954', ['Az ember tragédiája', 'Kis Vuk', 'Szép halál volt', 'Kék egér', 'Bírós emberek', 'Kisváros', 'David y el gigante de piedra', 'Kis Romulusz', 'Szomszédok', 'Frici, a vállalkozó szellem'], 'Actor', '')\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "('Tonja Walker', 'September 19, 1960', ['Dinner with the Hoffmans', 'Last Culprit', 'The Lie', 'Hospital General', 'Exiled Out East', 'Exiled Out East', 'Tainted Dreams', 'My Dog the Space Traveler', 'Excuse Me for Living', 'Max Payne 3'], 'ActressProducerWriter', '')\n",
      "La respuesta de la petición es: 200\n",
      "La respuesta de la petición es: 200\n",
      "('Gyula Buss', 'February 14, 1927', ['Ének a csodaszarvasról', 'Kisváros', 'Aranyoskáim', 'Új Gálvölgyi-show', 'Csillagvitéz', 'La ciudad de los gatos', 'Tizenötezer pengö jutalom', 'Kérem a következöt!', 'A három kövér', 'Csipike, az óriás törpe'], 'Actor', '')\n"
     ]
    }
   ],
   "source": [
    "csv = \"info_peliculas_Drama_actores.csv\"\n",
    "# csv = input(\"Introduce el género del que quieres conseguir la información\")\n",
    "try:\n",
    "    peliculas_accion_sele = ExtraerDatosActoresSelenium(csv)\n",
    "    peliculas_accion_sele.pag_principal_google()\n",
    "except:\n",
    "    print(\"Hay algún error, comprueba que exista el fichero\")\n",
    "    # pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
